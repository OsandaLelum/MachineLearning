{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sure! I'd be happy to explain the cost function in linear regression for beginners in machine learning.\n",
        "\n",
        "In linear regression, the cost function is a measure of how well the model fits the training data. It quantifies the difference between the predicted values of the model and the actual values in the training dataset. The goal of linear regression is to minimize this cost function, which means finding the best-fitting line or hyperplane that represents the relationship between the input features and the target variable.\n",
        "\n",
        "In the case of simple linear regression, where there is only one input feature, the cost function is often represented using the mean squared error (MSE) formula. The MSE is calculated by taking the average of the squared differences between the predicted values (obtained from the linear regression equation) and the actual values in the training data. Mathematically, it can be expressed as:\n",
        "\n",
        "MSE = (1/n) * Σ(yᵢ - ŷᵢ)²\n",
        "\n",
        "where n is the number of training examples, yᵢ represents the actual value of the target variable for the i-th example, and ŷᵢ represents the predicted value given by the linear regression equation.\n",
        "\n",
        "The cost function essentially penalizes the model for making large errors in its predictions. By minimizing the MSE, the model learns to adjust its parameters (slope and intercept in the case of simple linear regression) in order to obtain the best-fitting line that minimizes the overall squared difference between the predicted and actual values.\n",
        "\n",
        "To find the optimal parameters that minimize the cost function, an algorithm called gradient descent is commonly used in linear regression. Gradient descent iteratively updates the parameters by taking steps proportional to the negative gradient of the cost function, gradually converging towards the minimum.\n",
        "\n",
        "By minimizing the cost function using gradient descent, the linear regression model learns the optimal parameters that best fit the training data, allowing it to make predictions on new, unseen data.\n",
        "\n",
        "It's worth noting that the cost function and optimization techniques may vary depending on the type of regression problem and the specific requirements of the model. However, the concept of minimizing the cost function to find the best fit remains fundamental in many regression algorithms, including linear regression."
      ],
      "metadata": {
        "id": "66tdEws5pwkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z4PtZo79qlKZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m58SCCLfoWyJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_cost(X, y, theta):\n",
        "    \"\"\"\n",
        "    Compute the cost function for linear regression.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input features, represented as a matrix of shape (m, n+1)\n",
        "    y -- target variable, represented as a vector of shape (m, 1)\n",
        "    theta -- parameters of the linear regression model, represented as a vector of shape (n+1, 1)\n",
        "\n",
        "    Returns:\n",
        "    cost -- the computed cost value\n",
        "    \"\"\"\n",
        "\n",
        "    m = len(y)  # number of training examples\n",
        "\n",
        "    # Compute predictions\n",
        "    predictions = np.dot(X, theta)\n",
        "\n",
        "    # Compute squared differences\n",
        "    squared_diff = np.square(predictions - y)\n",
        "\n",
        "    # Compute cost\n",
        "    cost = (1 / (2 * m)) * np.sum(squared_diff)\n",
        "\n",
        "    return cost\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "X = np.array([[1, 2], [1, 3], [1, 4]])  # input features\n",
        "y = np.array([[3], [4], [5]])  # target variable\n",
        "theta = np.array([[1], [2]])  # parameters\n",
        "\n",
        "cost = compute_cost(X, y, theta)\n",
        "print(\"Cost:\", cost)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlXf10ctp8FK",
        "outputId": "8ada4295-0a1a-4f0c-b73a-c8ebd2888979"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost: 4.833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[1, 2], [1, 3], [1, 4]])  # input features\n",
        "y = np.array([[3], [4], [5]])  # target variable\n",
        "theta = np.array([[1], [2]])  # parameters\n",
        "\n",
        "cost = compute_cost(X, y, theta)\n",
        "print(\"Cost:\", cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-YWZLw5rEde",
        "outputId": "f5317682-7961-4871-e6db-7b0d6aa79204"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost: 4.833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[1, 1], [1, 2], [1, 3], [1, 4]])  # input features\n",
        "y = np.array([[2], [3], [4], [5]])  # target variable\n",
        "theta = np.array([[1], [1]])  # parameters\n",
        "\n",
        "cost = compute_cost(X, y, theta)\n",
        "print(\"Cost:\", cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8daD-wMdrdNT",
        "outputId": "d38594aa-e87c-4b33-c7cb-af90f93f09b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost: 0.0\n"
          ]
        }
      ]
    }
  ]
}