{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install hydra-core\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnIOLXa7yp_2",
        "outputId": "89eeee50-ad1e-4920-e4c7-b55c498a0a6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (23.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl-6e0zBzmMA",
        "outputId": "6e811df2-513c-4a8c-cd06-f794fd533267"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.0.94)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.1+cu118)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.22.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0+cu118)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5eldzorz3Am",
        "outputId": "a6f76d48-819c-4173-d4dc-6963501ac184"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.0.94)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.1+cu118)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.22.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0+cu118)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep_sort_pytorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYHyVDfY1Rha",
        "outputId": "2ecba956-3acd-4e37-d347-be1f3394df68"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement deep_sort_pytorch (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for deep_sort_pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "MNvHAbLjyiXv",
        "outputId": "b3f27230-fa03-4442-a8e3-0b171b75a3f6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5061bc0ae040>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_sort_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_sort_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_sort\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepSort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deep_sort_pytorch'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import hydra\n",
        "import torch\n",
        "import argparse\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "from ultralytics.yolo.engine.predictor import BasePredictor\n",
        "#from ultralytics.yolo.config import DEFAULT_CONFIG\n",
        "from ultralytics.yolo.utils import ROOT, ops\n",
        "from ultralytics.yolo.utils.checks import check_imgsz\n",
        "from ultralytics.yolo.utils.plotting import Annotator, colors, save_one_box\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "import cv2\n",
        "from deep_sort_pytorch.utils.parser import get_config\n",
        "from deep_sort_pytorch.deep_sort import DeepSort\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
        "data_deque = {}\n",
        "\n",
        "deepsort = None\n",
        "\n",
        "\n",
        "def count(founded_classes, im0):\n",
        "  model_values=[]\n",
        "  aligns=im0.shape\n",
        "  #align_bottom variable represents the height of the image\n",
        "  align_bottom=aligns[0]/14\n",
        "  #align width variable represnts the width of the image\n",
        "  align_right=(aligns[1]/1.2)\n",
        "  for i,(k,v) in enumerate (founded_classes.items()):\n",
        "    a=f\"{k} = {v}\"\n",
        "    model_values.append(v)\n",
        "    align_bottom=align_bottom+35\n",
        "    cv2.line(im0, (int(align_right),int(align_bottom-10)), (int(align_right+210),int(align_bottom-10)), (0,255,0), 40) \n",
        "    cv2.putText(im0,str(a),(int(align_right),int(align_bottom)),cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255),2,cv2.LINE_AA)\n",
        "\n",
        "class GenderClassifier ():\n",
        "    def __init__(self, weights) :\n",
        "        self.weights = weights\n",
        "        self.model = self.load_model()\n",
        "\n",
        "    def preprocess_image (self, image):\n",
        "        face_crop = cv2.resize(image, (100,100))\n",
        "        face_crop = face_crop.astype(\"float\") / 255.0\n",
        "        face_crop = img_to_array(face_crop)\n",
        "        face_crop = np.expand_dims(face_crop, axis=0)\n",
        "        return face_crop\n",
        "    \n",
        "    def load_model(self):\n",
        "        model = load_model(self.weights)\n",
        "        return model\n",
        "\n",
        "    def predict (self, image):\n",
        "        classes = ['man','woman']\n",
        "        face_crop = self.preprocess_image(image)\n",
        "        conf = self.model.predict(face_crop)[0] # model.predict return a 2D matrix, ex: [[9.9993384e-01 7.4850512e-05]]\n",
        "        # get label with max accuracy\n",
        "        idx = np.argmax(conf)\n",
        "        label = classes[idx]\n",
        "        label = \"{}\".format(label)\n",
        "        return label\n",
        "\n",
        "def init_tracker():\n",
        "    global deepsort\n",
        "    cfg_deep = get_config()\n",
        "    cfg_deep.merge_from_file(\"deep_sort_pytorch/configs/deep_sort.yaml\")\n",
        "\n",
        "    deepsort= DeepSort(cfg_deep.DEEPSORT.REID_CKPT,\n",
        "                            max_dist=cfg_deep.DEEPSORT.MAX_DIST, min_confidence=cfg_deep.DEEPSORT.MIN_CONFIDENCE,\n",
        "                            nms_max_overlap=cfg_deep.DEEPSORT.NMS_MAX_OVERLAP, max_iou_distance=cfg_deep.DEEPSORT.MAX_IOU_DISTANCE,\n",
        "                            max_age=cfg_deep.DEEPSORT.MAX_AGE, n_init=cfg_deep.DEEPSORT.N_INIT, nn_budget=cfg_deep.DEEPSORT.NN_BUDGET,\n",
        "                            use_cuda=True)\n",
        "##########################################################################################\n",
        "def xyxy_to_xywh(*xyxy):\n",
        "    \"\"\"\" Calculates the relative bounding box from absolute pixel values. \"\"\"\n",
        "    bbox_left = min([xyxy[0].item(), xyxy[2].item()])\n",
        "    bbox_top = min([xyxy[1].item(), xyxy[3].item()])\n",
        "    bbox_w = abs(xyxy[0].item() - xyxy[2].item())\n",
        "    bbox_h = abs(xyxy[1].item() - xyxy[3].item())\n",
        "    x_c = (bbox_left + bbox_w / 2)\n",
        "    y_c = (bbox_top + bbox_h / 2)\n",
        "    w = bbox_w\n",
        "    h = bbox_h\n",
        "    return x_c, y_c, w, h\n",
        "\n",
        "def xyxy_to_tlwh(bbox_xyxy):\n",
        "    tlwh_bboxs = []\n",
        "    for i, box in enumerate(bbox_xyxy):\n",
        "        x1, y1, x2, y2 = [int(i) for i in box]\n",
        "        top = x1\n",
        "        left = y1\n",
        "        w = int(x2 - x1)\n",
        "        h = int(y2 - y1)\n",
        "        tlwh_obj = [top, left, w, h]\n",
        "        tlwh_bboxs.append(tlwh_obj)\n",
        "    return tlwh_bboxs\n",
        "\n",
        "def compute_color_for_labels(label):\n",
        "    \"\"\"\n",
        "    Simple function that adds fixed color depending on the class\n",
        "    \"\"\"\n",
        "    if label == 0: #person\n",
        "        color = (85,45,255)\n",
        "    elif label == 2: # Car\n",
        "        color = (222,82,175)\n",
        "    elif label == 3:  # Motobike\n",
        "        color = (0, 204, 255)\n",
        "    elif label == 5:  # Bus\n",
        "        color = (0, 149, 255)\n",
        "    else:\n",
        "        color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
        "    return tuple(color)\n",
        "\n",
        "def draw_border(img, pt1, pt2, color, thickness, r, d):\n",
        "    x1,y1 = pt1\n",
        "    x2,y2 = pt2\n",
        "    # Top left\n",
        "    cv2.line(img, (x1 + r, y1), (x1 + r + d, y1), color, thickness)\n",
        "    cv2.line(img, (x1, y1 + r), (x1, y1 + r + d), color, thickness)\n",
        "    cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness)\n",
        "    # Top right\n",
        "    cv2.line(img, (x2 - r, y1), (x2 - r - d, y1), color, thickness)\n",
        "    cv2.line(img, (x2, y1 + r), (x2, y1 + r + d), color, thickness)\n",
        "    cv2.ellipse(img, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness)\n",
        "    # Bottom left\n",
        "    cv2.line(img, (x1 + r, y2), (x1 + r + d, y2), color, thickness)\n",
        "    cv2.line(img, (x1, y2 - r), (x1, y2 - r - d), color, thickness)\n",
        "    cv2.ellipse(img, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness)\n",
        "    # Bottom right\n",
        "    cv2.line(img, (x2 - r, y2), (x2 - r - d, y2), color, thickness)\n",
        "    cv2.line(img, (x2, y2 - r), (x2, y2 - r - d), color, thickness)\n",
        "    cv2.ellipse(img, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness)\n",
        "\n",
        "    cv2.rectangle(img, (x1 + r, y1), (x2 - r, y2), color, -1, cv2.LINE_AA)\n",
        "    cv2.rectangle(img, (x1, y1 + r), (x2, y2 - r - d), color, -1, cv2.LINE_AA)\n",
        "    \n",
        "    cv2.circle(img, (x1 +r, y1+r), 2, color, 12)\n",
        "    cv2.circle(img, (x2 -r, y1+r), 2, color, 12)\n",
        "    cv2.circle(img, (x1 +r, y2-r), 2, color, 12)\n",
        "    cv2.circle(img, (x2 -r, y2-r), 2, color, 12)\n",
        "    \n",
        "    return img\n",
        "\n",
        "def UI_box(x, img, color=None, label=None, line_thickness=None):\n",
        "    # Plots one bounding box on image img\n",
        "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(tl - 1, 1)  # font thickness\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        cv2.rectangle(img, (c1[0], c1[1] - t_size[1] -3), (c1[0] + t_size[0], c1[1]+3), color,-1,  cv2.LINE_AA)\n",
        "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "\n",
        "\n",
        "def draw_boxes(img, bbox, names,object_id, identities=None, offset=(0, 0)):\n",
        "    #cv2.line(img, line[0], line[1], (46,162,112), 3)\n",
        "    classifier = GenderClassifier(\"model.h5\")\n",
        "    height, width, _ = img.shape\n",
        "    # remove tracked point from buffer if object is lost\n",
        "    for key in list(data_deque):\n",
        "      if key not in identities:\n",
        "        data_deque.pop(key)\n",
        "\n",
        "    for i, box in enumerate(bbox):\n",
        "        x1, y1, x2, y2 = [int(i) for i in box]\n",
        "        x1 += offset[0]\n",
        "        x2 += offset[0]\n",
        "        y1 += offset[1]\n",
        "        y2 += offset[1]\n",
        "        roi = img[y1:y2, x1:x2]\n",
        "        gender_label = \"\"\n",
        "        if (roi.shape[0]) > 10 or (roi.shape[1]) > 10:\n",
        "            gender_label = classifier.predict(roi)\n",
        "        Y = y1 - 10 if y1 - 10 > 10 else y1 + 10\n",
        "        text = gender_label\n",
        "        # get ID of object\n",
        "        id = int(identities[i]) if identities is not None else 0\n",
        "        label = '{}{:d}'.format(\"\", id) + \":\"+ '%s' % (text)\n",
        "        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        text_w, text_h = text_size[0]\n",
        "        cv2.rectangle(img, (x1,y1), (x2, y2), (0,103,255), thickness=2, lineType=cv2.LINE_AA)\n",
        "        cv2.line(img, (x1, Y), (text_w+x1, Y), (121, 233, 121), 30)\n",
        "        cv2.putText(img, label, (x1, Y),  cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.6, (255, 255, 255), 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "class DetectionPredictor(BasePredictor):\n",
        "\n",
        "    def get_annotator(self, img):\n",
        "        return Annotator(img, line_width=self.args.line_thickness, example=str(self.model.names))\n",
        "\n",
        "    def preprocess(self, img):\n",
        "        img = torch.from_numpy(img).to(self.model.device)\n",
        "        img = img.half() if self.model.fp16 else img.float()  # uint8 to fp16/32\n",
        "        img /= 255  # 0 - 255 to 0.0 - 1.0\n",
        "        return img\n",
        "\n",
        "    def postprocess(self, preds, img, orig_img):\n",
        "        preds = ops.non_max_suppression(preds,\n",
        "                                        self.args.conf,\n",
        "                                        self.args.iou,\n",
        "                                        agnostic=self.args.agnostic_nms,\n",
        "                                        max_det=self.args.max_det)\n",
        "\n",
        "        for i, pred in enumerate(preds):\n",
        "            shape = orig_img[i].shape if self.webcam else orig_img.shape\n",
        "            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], shape).round()\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def write_results(self, idx, preds, batch):\n",
        "        p, im, im0 = batch\n",
        "        all_outputs = []\n",
        "        log_string = \"\"\n",
        "        if len(im.shape) == 3:\n",
        "            im = im[None]  # expand for batch dim\n",
        "        self.seen += 1\n",
        "        im0 = im0.copy()\n",
        "        if self.webcam:  # batch_size >= 1\n",
        "            log_string += f'{idx}: '\n",
        "            frame = self.dataset.count\n",
        "        else:\n",
        "            frame = getattr(self.dataset, 'frame', 0)\n",
        "\n",
        "        self.data_path = p\n",
        "        save_path = str(self.save_dir / p.name)  # im.jpg\n",
        "        self.txt_path = str(self.save_dir / 'labels' / p.stem) + ('' if self.dataset.mode == 'image' else f'_{frame}')\n",
        "        log_string += '%gx%g ' % im.shape[2:]  # print string\n",
        "        self.annotator = self.get_annotator(im0)\n",
        "\n",
        "        det = preds[idx]\n",
        "        all_outputs.append(det)\n",
        "        if len(det) == 0:\n",
        "            return log_string\n",
        "        founded_classes = {}\n",
        "        for c in det[:, 5].unique():\n",
        "            n = (det[:, 5] == c).sum()  # detections per class\n",
        "            class_index=int(c)\n",
        "            count_of_object=int(n)\n",
        "            founded_classes[self.model.names[class_index]]=int(n)\n",
        "            log_string += f\"{n} {self.model.names[int(c)]}{'s' * (n > 1)}, \"\n",
        "            count(founded_classes=founded_classes,im0=im0)\n",
        "\n",
        "        # write\n",
        "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "        xywh_bboxs = []\n",
        "        confs = []\n",
        "        oids = []\n",
        "        outputs = []\n",
        "        for *xyxy, conf, cls in reversed(det):\n",
        "            x_c, y_c, bbox_w, bbox_h = xyxy_to_xywh(*xyxy)\n",
        "            xywh_obj = [x_c, y_c, bbox_w, bbox_h]\n",
        "            xywh_bboxs.append(xywh_obj)\n",
        "            confs.append([conf.item()])\n",
        "            oids.append(int(cls))\n",
        "        xywhs = torch.Tensor(xywh_bboxs)\n",
        "        confss = torch.Tensor(confs)\n",
        "          \n",
        "        outputs = deepsort.update(xywhs, confss, oids, im0)\n",
        "        if len(outputs) > 0:\n",
        "            bbox_xyxy = outputs[:, :4]\n",
        "            identities = outputs[:, -2]\n",
        "            object_id = outputs[:, -1]\n",
        "            \n",
        "            draw_boxes(im0, bbox_xyxy, self.model.names, object_id,identities)\n",
        "\n",
        "        return log_string\n",
        "\n",
        "\n",
        "@hydra.main(version_base=None, config_path=str(DEFAULT_CONFIG.parent), config_name=DEFAULT_CONFIG.name)\n",
        "def predict(cfg):\n",
        "    init_tracker()\n",
        "    cfg.model = cfg.model or \"yolov8n.pt\"\n",
        "    cfg.imgsz = check_imgsz(cfg.imgsz, min_dim=2)  # check image size\n",
        "    cfg.source = cfg.source if cfg.source is not None else ROOT / \"assets\"\n",
        "    predictor = DetectionPredictor(cfg)\n",
        "    predictor()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    predict()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YUVl8Eczyp5T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}